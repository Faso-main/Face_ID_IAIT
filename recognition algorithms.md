# Алгоритмы, методы распознования

## Научные статьи
- **ASMNet: a Lightweight Deep Neural Network for Face Alignment and Pose
 Estimation**  
  Ali Pourramezan F, Hojjat A. and Mohammad M (2021). 
  [OpenAccess @ CVPR 2017](https://openaccess.thecvf.com/content/CVPR2021W/AMFG/papers/Fard_ASMNet_A_Lightweight_Deep_Neural_Network_for_Face_Alignment_and_CVPRW_2021_paper.pdf)

## Как работает ASM face landmarks
  *ASM (Active Shape Model, т. н. «активная модель формы») для определения ориентиров (landmarks) на лице — это подход, который использует статистический анализ для моделирования и последующего поиска   
  характерных точек на изображении лица. Работа модели делится на два основных этапа: обучение (тренировка) и поиск оптимального соответствия (фиттинг).
  - Обучение и статистическое представление формы
  На этапе обучения собирается набор изображений, на которых вручную размечены ключевые точки лица (например, контуры глаз, носа, рта и других характерных деталей). Эти размеченные данные используются для 
  статистического анализа формы. С помощью методов, таких как анализ главных компонент (PCA), вычисляются основные моды вариаций, которые описывают, как может изменяться форма лица в зависимости от 
  различных факторов (выражения, ракурс, возраст и т.д.). Таким образом, получается модель, способная охватить множество возможных деформаций лица, но при этом сохраняющая общую конфигурацию характерных 
  точек.

  - Поиск оптимального соответствия (фиттинг)
  Когда новая фотография обрабатывается, ASM начинает с некого начального приближения положения ключевых точек. Далее для каждой точки производится итеративный поиск вдоль направления, перпендикулярного к
  контуру (так называемый профиль), чтобы определить наиболее вероятное её местоположение на основе локальных особенностей изображения (например, изменения яркости или градиентов). При этом положение всех
  точек корректируется с учётом ограничений, заданных статистической моделью, что позволяет не только точно «прищелкнуть» каждую точку, но и сохранить согласованность общей формы лица. Такой подход
  помогает системе быть устойчивой к шуму и локальным помехам, поскольку возможные ошибки коррекции отдельных точек компенсируются глобальными ограничениями модели.

  - Интеграция ASM в современные глубокие сети
  Современные методы, такие как ASMNet, объединяют идеи классических активных моделей формы с возможностями глубокого обучения. В таких системах используется специальная функция потерь (ASM-assisted loss),
  которая на первых этапах обучения направляет сеть к освоению сглаженного распределения ключевых точек, а затем постепенно «зашивает» детали до максимально точных положений. Такой мультиядерный подход
  (multitask learning), когда одновременно решаются задачи выравнивания ключевых точек и оценки позы лица, позволяет достигать высокой точности при небольшом количестве параметров сети.

  Таким образом, ASM для определения ориентиров на лице сочетает в себе мощь статистического анализа и итеративного поиска для точного позиционирования ключевых точек, а его современные воплощения в виде 
  нейросетевых архитектур способны адаптировать и улучшать традиционные методы за счёт обучения на больших данных и интеграции дополнительных задач, таких как оценка позы.*

## Интеграция ASM в архитектуры глубокого обучения
  *В современных приложениях для распознавания лиц ASM (активная модель формы) в первую очередь используется для точного выравнивания лиц перед основной фазой распознавания. Традиционно, ASM опирается на   
  статистический анализ набора размеченных изображений, где для каждого лица заранее заданы ключевые точки (landmarks). Это позволяет модели изучать типичные вариации формы лица, а затем в режиме реального 
  времени корректировать положение этих точек на новых изображениях, даже при изменении выражения, ракурса или при наличии незначительных помех в изображении.

  Современные системы зачастую интегрируют ASM в более сложные архитектуры глубокого обучения. Например, модели вроде ASMNet используют концепцию ASM для формирования вспомогательной функции потерь («ASM-
  assisted loss»), которая направляет нейросеть к обучению более гладкого и консистентного распределения точек. Такой подход помогает системе аккуратно проверять и корректировать положение ориентиров на 
  лице, что особенно важно для дальнейшего этапа распознавания. Благодаря такому совместному обучению (multitask learning) сеть не только обнаруживает ключевые точки, но и оценивает позу лица, повышая 
  общую устойчивость системы даже при наличии сложных условий съёмки3.

  В итоге, использование ASM в современных приложениях позволяет добиться высокой точности выравнивания лиц, что критически важно для надежного распознавания. Этот метод помогает нормализовать изображение, 
  компенсируя вариации в ракурсе и освещении, а также минимизировать локальные ошибки за счет глобальных ограничений формы. Такой гибридный подход, объединяющий классические статистические методы и   
  возможности глубокого обучения, становится незаменимым инструментом в решениях по распознаванию лиц, обеспечивая баланс между качеством обработки и вычислительной эффективностью.*

## Каскадная регрессия
  *Каскадная регрессия — это метод, который разбивает сложную задачу предсказания (например, определение координат ключевых точек на лице) на серию более простых этапов. Идея заключается в последовательном 
  уточнении начального предсказания при помощи нескольких регрессоров, которые работают один за другим в виде каскада.
  
  Как работает каскадная регрессия в контексте обработки изображений:
  - Начальное приближение: На вход алгоритму поступает примерное положение интересующих характеристик (например, средняя форма лица).
  - Последовательное уточнение: Первый регрессор анализирует изображение, сравнивает начальное приближение с реальными признаками в данных и вычисляет корректирующие смещения (остаточную ошибку). Далее   
  обновлённое предсказание используется следующим регрессором, который повторно ищет ошибку и снова её корректирует.
  - Итеративное улучшение: Повторяя этот процесс на каждом этапе (каждый регрессор специализируется на устранивании остаточной ошибки предыдущего шага), система постепенно приближается к максимально
    точному определению нужных параметров.

  Такой подход позволяет решать задачу поэтапно — каждая итерация исправляет недочёты предыдущего шага, делая общую модель более устойчивой к сложностям исходных данных (например, вариациям в освещении,   
  позе или экспрессии). Именно благодаря итеративной корректировке каскадная регрессия часто используется в задачах выравнивания лиц (face alignment) в системах распознавания лиц или оценки мимики.

  Каскадная регрессия обладает рядом преимуществ:
 - Эффективность: Каждый отдельный регрессор решает упрощённую задачу, что ускоряет процесс расчётов.
 - Гибкость: Модель адаптируется к различным ошибкам, корректируя предсказание в зависимости от данных.
 - Лёгкость интеграции: Метод хорошо сочетается с другими алгоритмами компьютерного зрения, позволяя развивать более сложные системы на его основе.

  Этот подход активно применяется в реальном времени, где требуется высокая точность при ограниченных вычислительных ресурсах. В последние годы его дополняют методами глубокого обучения, что даёт 
  дополнительное преимущество в обработке сложных изображений.
  
  Совмещение каскадной регрессии с нейронными сетями создаёт гибридные системы, которые обеспечивают еще большую устойчивость и точность. Такие подходы широко применяются в современных системах 
  компьютерного зрения, где требуется баланс между вычислительной эффективностью и качеством предсказаний.*

## Principal Component Analysis (PCA)
  *Анализ главных компонент (Principal Component Analysis, PCA) — это статистический метод для снижения размерности данных, который позволяет преобразовывать исходный набор взаимосвязанных переменных в 
  новый набор независимых переменных, называемых главными компонентами. Главная идея PCA заключается в поиске направлений (компонент), вдоль которых данные проявляют наибольшую дисперсию, а следовательно, 
  и наибольшую информационную составляющую.

  Основные этапы работы PCA
  - Центрирование данных: Прежде чем приступить к анализу, данные центрируются, то есть из каждого измерения вычитается его среднее значение. Это позволяет расположить данные таким образом, чтобы их центр
    масс совпадал с началом координат.
  - Вычисление ковариационной матрицы: Для центрированных данных рассчитывается матрица ковариаций, которая отражает степень линейной взаимосвязи между различными измерениями.
  - Нахождение собственных векторов и собственных значений: Далее производится разложение ковариационной матрицы на собственные векторы и собственные значения. Собственные векторы указывают направления, в
    которых данные изменяются наиболее существенно, а собственные значения отражают величину этой вариации.
  - Формирование новых переменных: Собственные векторы (главные компоненты) сортируются по убыванию собственных значений. Первые несколько компонентов обычно объясняют основную часть дисперсии в данных,
    поэтому их можно использовать для представления исходных данных в пространстве меньшей размерности.
  - Проекция исходных данных: Исходные данные проецируются на выбранное подпространство, что позволяет уменьшить размерность с сохранением как можно большего количества информации.

  Практическое применение PCA
  Снижение размерности: PCA широко используется для уменьшения количества переменных в наборах данных, что помогает визуализировать данные и снижает вычислительную нагрузку при последующем анализе.
  Предобработка данных: В задачах машинного обучения PCA помогает устранить коррелированность предикторов, улучшая качество моделей.
  Улучшение визуализации: При работе с высокоразмерными данными метод позволяет отобразить их в двумерном или трехмерном пространстве, что существенно облегчает анализ кластеров и структур данных.
  Обработка сигналов и изображений: PCA применяется для выделения наиболее информативных признаков, например, в распознавании лиц или для устранения шума в изображениях.

  Таким образом, PCA является мощным и широко используемым инструментом в статистическом анализе данных, позволяющим эффективно обрабатывать и анализировать информацию даже в случае большого числа 
  переменных*

  Дополнительно:
  Вычисление ковариационной матрицы.

  
## Open-source проекты
- **ASMNet**  
  [HuggingFace]([https://huggingface.co/aliprf/ASMNet])  
  *Реализация ASMNet в TensorFlow*
